---
layout: post
current: post
cover: assets/images/water.png
navigation: True
title: "1.5 테스트와 검증"
date: 2020-04-29
tags: ML Scikit-Learn
class: post-template
subclass: 'post'
author: kwang
---

## 1.5 테스트와 검증

모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법은 새로운 샘플에 실제로 적용해 보는 것입니다. 이를 위해 실제 서비스에 모델을 넣고 잘 동작하는지 모니터링하는 방법이 있습니다. 이 방법이 괜찮긴 하지만 만약 모델이 아주 나쁟다면 고객이 불만을 토로할 테니 좋은 생각이 아닙니다.

더 나은 방법은 훈련 데이터를 훈련 세트와 테스트 세트 두 개로 나누는 것입니다. 이름에서도 알 수 있듯이 훈련 세트를 사용해 모델을 훈련시키고 테스트 세트를 사용해 모델을 테스트합니다. 새로운 샘플에 대한 오류 비율을 일반화 오차 generalization error(또는 외부 샘플 오차 out-of sample error)라고 하며, 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추청값(estimation)을 얻습니다. 이 값은 이전에 본 적이 없는 새로운 샘플에 모델이 얼마나 잘 작동할지 알려줍니다. 

훈련 오차가 낮지만(즉, 훈련 세트에서 모델의 오차가 적음) 일반화 오차가 높다면 이는 모델이 훈련 데이터에 과대적합되었다는 뜻입니다.
-tip : 보통 데이터의 80%를 훈련에 사용하고 20%는 테스트용으로 떼어놓습니다.

모델 평가는 아주 간단합니다. 그냥 테스트 세트를 사용하면 됩니다. 두 모델(선형 모델과 다항 모델) 중 어떤 것을 선택할지 갈등하고 있다고 합시다. 어떻게 결정할 수 있을까요? 두 모델 모두 훈련 세트로 훈련시키고 테스트 세트를 사용해 얼마나 잘 일반화되는지 비교해 보면 됩니다. 

이제 선형 모델이 더 잘 일반화되었다고 가정하고 과대적합을 피하기 위해 규제를 적용하려고 합니다. 이때 하이퍼파라미터 값을 어떻게 선택할까요? 100개의 하이퍼파라미터 값으로 100개의 다른 모델을 훈련시키는 방법이 있습니다. 일반화 오차가 가장 낮은 모델(5%라고 합시다)을 만드는 최적의 하이퍼파라미터를 찾았다고 가정합시다.
이제 이 모델을  실제 서비스에 투입합니다. 하지만 성능이 예상만큼 좋지 않고 오차를 15%나 만듭니다. 왜 그럴까요?

일반화 오차를 테스트 세트에서 여러 번 측정했으므로 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만들었기 때문입니다. 이는 모델이 새로운 데이터에 잘 작동하지 않을 수 있다는 뜻입니다. 
이 문제에 대한 일반적인 해결방법은 검증 세트 validation set라 부르는 두번째 홀드아웃 holdout 세트를 만드는 것입니다. 훈련 세트를 사용해 다양한 하이퍼파라미터로 여러 모델을 훈련시키고 검증 세트에서 최상의 성능을 내는 모델과 하이퍼파라미터를 선택합니다. 만족스러운 모델을 찾으면 일반화 오차의 추정값을 얻기 위해 테스트 세트로 단 한 번의 최종 테스트를 합니다. 
훈련 데이터에서 검증 세트로 너무 많은 양의 데이터를 뺏기지 않기 위해 일반적으로 교차 검증(cross-validation)기법을 사용합니다. 훈련 세트를 여러 서브셋으로 나누고 각 모델을 이 서브셋의 조합으로 훈련시키고 나머지 부분으로 검증합니다. 모델과 하이퍼파라미터가 선택되면 전체 훈련 데이터를 사용하여 선택한 하이퍼파라미터로 최종 모델을 훈련시키고 테스트 세트에서 일반화 오차를 측정합니다.

---
공짜 점심 없음 이론
모델은 관측한 것을 간소화한 것입니다. 간소화의 의미는 새로운 샘플에 일반적이지 않을 것 같은 불필요한 세부사항을 제거하는 것입니다. 그러나 어떤 데이터를 버리고 어떤 데이터를 남길지 정하기 위해 가정을 해야 합니다. 예를 들어 선형 모델은 데이터가 근본적으로 선형이고 샘플과 직선 사이의 거리는 무시할 수 있는 잡음이라고 가정합니다.

1996년에 발표한 유명한 논문에서 데이비드 월퍼트는 데이터에 관해 완벽하게 어떤 가정도 하지 않으면 한 모델을 다른 모델보다 선호할 근거가 없음을 보였습니다. 이를 공짜 점심 없음 No Free Lunch(NFL) 이론이라고 합니다. 어떤 데이터셋에서는 선형 모델이 가장 잘 들어맞지만 다른 데이터셋에서는 신경망이 잘 들어맞습니다. 경험하기 전에 더 잘 맞을 거라고 보장할 수 있는 모델은 없습니다. (이 이론의 이름이 유래된 이유입니다) 어떤 모델이 최선인지 확실히 아는 유일한 방법은 모든 모델을 평가해보는 것 뿐입니다. 이것이 불가능하기 때문에 실정에서는 데이터에 관해 타당한 가정을 하고 적절한 모델 몇 가지만 평가합니다. 예를 들어 간단한 작업에서는 규제의 수준이 다양한 선형 모델을 평가하고, 복잡한 문제라면 여러 가지 신경망을 평가합니다.
---

## 1.6 연습문제

이 장에서는 머신러닝에서 가장 중요한 개념을 다뤘습니다. 다음 장에서는 조금 더 깊게 들어가고 더 많은 코드를 작성하겠습니다. 그 전에 다음 질문에 대한 답을 찾아보세요.

1. 머신러닝을 어떻게 정의할 수 있나요?
2. 머신러닝이 도움을 줄 수 있는 문제 유형 네가지를 말해보세요.
3. 레이블된 훈련 세트란 무엇인가요?
4. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?
5. 보편적인 비지도 학습 작업 네 가지는 무엇인가요?
6. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?
7. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?
8. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?
9. 온라인 학습 시스템이 무엇인가요?
10. 외부 메모리 학습이 무엇인가요?
11. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?
12. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요?
13. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?
14. 머신러닝의 주요 도전 과제는 무엇인가요?
15. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책 세 가지는 무엇인가요?
16. 테스트 세트가 무엇이고 왜 사용해야 하나요?
17. 검증 세트의 목적은 무엇인가요?
18. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요?
19. 교차 검증이 무엇이고, 왜 하나의 검증 세트보다 선호하나요?

---

출처 및 저작권 : Hands-On Machine Learning with Scikit-Learn & TensorFlow
아래는 공부를 위해 필사를 하며 노트한 내용입니다.